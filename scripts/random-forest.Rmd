---
title: "Random Forest Modeling"
author: "Wesley Rancher, Hana Matsumoto"
date: "2025-1-2"
output: html_document
editor_options:
    chunk_output_type: console
---

Random Forest Classification Using Tidy Models

```{r Libraries}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.width = 6, fig.align = 'center')
required_packages <- c("dplyr", "terra", "randomForest", "stringr", "tidyr", 
                       "tidymodels", "ggplot2", "vip", "usemodels", "doParallel", "vegan")
install.packages(setdiff(required_packages, installed.packages()[,"Package"]))
lapply(required_packages, library, character.only = TRUE)
```

# Read in CSVs output from GEE Sampling

```{r Iterate Over PV CSVs and Store Pred Var DF}
# read in extracted predictors from gee
output_dir <- "data/output/csv/cleaned/GEE_Sampling_Data_BiomassLandisRegion/"
extracted_dfs <- list.files(output_dir, pattern = "PixelVals_Interior_.*\\.csv", full.names = TRUE)
# if iterating
pv_dfs_all_years <- list()
for (i in seq_along(extracted_dfs)){
  extracted_df <- read.csv(extracted_dfs[[i]])
  pv_dataframe <- left_join(spp_biomass_plots, 
                            extracted_df, by = "PSP")%>%#join where we have tree meas.
                  mutate(across(everything(), ~ na_if(.x, -9999)))
  
  pv_dataframe <- pv_dataframe %>%
    select( -c(1:4, 10,13)) %>%#change this based on structure of df
    rename(y = Latitude.y, x = Longitude.y)
  

  pv_dfs_all_years[[i]] <- na.omit(pv_dataframe)
  glimpse(pv_dfs_all_years[[i]])
}
```

## Read in tiffs output by GEE

```{r Read in GEE Ouput Maps}
#read in rasters from gee
gee_dir <- "data/output/gee/"
list_of_files <- list.files(gee_dir, pattern = "FullComp_Dalton_.*\\.tif$", full.names = TRUE)
pv_composites <- lapply(list_of_files, rast)

#define function for creating xy bands
add_xy_bands <- function (raster) {
  
  raster_df <- as.data.frame(raster, xy = TRUE)
  
  xrast <- rast(ncol = ncol(raster), nrow = nrow(raster), crs = crs(raster))
  yrast <- rast(ncol = ncol(raster), nrow = nrow(raster), crs = crs(raster))
  
  values(xrast) <- raster_df$x
  values(yrast) <- raster_df$y
  names(xrast) <- "x"
  names(yrast) <- "y"
  
  # set ext and add bands
  ext(xrast) <- ext(raster)
  ext(yrast) <- ext(raster)
  pv_rast_xy <- c(raster, xrast, yrast)
  return(pv_rast_xy)
}

#apply the function to the list of rasters
pv_composites_all_bands <- lapply(pv_composites, add_xy_bands)
```

Climate sensitive

```{r}
install.packages("RFMatrix")
```

## For each df we isolate the dependent variable (each tree spp), and tune the model and output results. Additionally, we 
## make spatial predictions for each dependent variable at each time step. 

```{r Tidy Models Workflows RF}
#out directories
out_dir_metrics <- "data/output/rf_results"
out_dir_figs <- "figures/"

#parallelize
# n_cores <- detectCores() -1 #leave free cores
# clus <- makeCluster(n_cores)
# registerDoParallel(clus)

#lists for storing output
model_metrics_all_years <- list()

# years <- 2000:2023
# index <- 1:24
# loop over each pv dataframe and drop highly correlated vars and Random Forest
# foreach(year_id = seq_along(pv_dfs_all_years), .combine = 'list',
#                      .packages = c("tidyverse", "tidymodels", "randomForest",
#                                    "dplyr", "ggplot2")) %dopar% {
years <- 2000:2023
index <- 1:24
for (i in seq_along(years))  {
  year <- years[i]  
  list_id <- index[i]
  pv_dataframe <- pv_dfs_all_years[[list_id]]
  
  #reduce predictors using correlation metrics
  model_metrics <- list()
  response_vars <- c("resin_birch", "black_spruce", 
                     "white_spruce", "black_cottonwood", "quaking_aspen")
  #response <- "black_spruce"
  for (response in response_vars) {
    #split data
    raw_bands <- c("blue_1", "blue_2", "blue_3",
                   "green_1", "green_2", "green_3",
                   "red_1", "red_2", "red_3",
                   "nir_1", "nir_2", "nir_3",
                   "swir1_1", "swir1_2", "swir1_3",
                   "swir2_1", "swir2_2", "swir2_3")

    predictors <- setdiff(names(pv_dataframe), response_vars) #rm response vars
    predictors <- setdiff(predictors, raw_bands)
    pv_split <- initial_split(pv_dataframe %>% 
                                select(all_of(response), 
                                       all_of(predictors)), 
                              prop = 0.80, 
                              strata = all_of(response)) 
    
    pv_train <- training(pv_split)
    pv_test <- testing(pv_split)
    
    
    #set formula
    formula <- as.formula(paste(response, "~", paste(predictors, collapse = "+")))
 
    #feature engineer and set up recipe
    rf_recipe <- recipe(formula = formula, data = pv_train) %>%
      step_nzv(all_predictors()) %>% #rm zero variance vars
      step_corr(all_numeric_predictors(), 
                threshold = 0.80, 
                use = "pairwise.complete.obs", 
                method = "pearson", 
                id = rand_id("corr"))
    vars_left <- rf_recipe$var_info[1]$variable 
    print(vars_left)
    
    
    #group predictor data
    pv_train_subset <- pv_train[, vars_left, drop = FALSE]
    response_subset <- pv_train_subset[, paste0(response), drop = FALSE]
    response_subset <- response_subset[[1]] 
    pv_train_subset_no_response <- pv_train_subset %>% select(-response)
    
    
    #dimensionality reduction
    pca <- prcomp(pv_train_subset_no_response, center = TRUE, scale. = TRUE)
    summary(pca)
    pca$rotation
    explained_variance <- summary(pca)$importance[2, ]
    
    year_chr <- as.character(year)
    plot(cumsum(explained_variance), type = 'b', 
     xlab = 'Number of Components', ylab = 'Cumulative Explained Variance',
     main = paste0(response, " ", year_chr))
    
    #meet the elbow
    pca_components <- pca$x[, 1:10]
    loadings <- pca$rotation[, 1:10]
    head(loadings)

    pca_df <- as.data.frame(pca_components)
    pca_df[[response]] <- response_subset
    
    #create revised recipe
    formula_revised <- as.formula(paste(response, "~ ."))
    rf_recipe_revised <- recipe(formula_revised, data = pca_df)
    
    #define models specs
    rf_spec_ranger <- 
      rand_forest(mtry = tune(), trees = tune(), min_n = tune()) %>% 
      set_mode("regression") %>% 
      set_engine("ranger", importance = "permutation")
    
    #hyperparam tuning grid
    ranger_grid <- expand.grid(
      mtry = seq(2, min(ncol(pv_dataframe) - 1, 20), 5),
      trees = 500,
      min_n = seq(3, 9, 3))

    #model workflow
    ranger_workflow <- workflow() %>% 
      add_recipe(rf_recipe) %>% 
      add_model(rf_spec_ranger)
    
    # resample and collect model metrics
    set.seed(70684)
    #set.seed(1999)
    pv_folds <- vfold_cv(pv_train, v = 10, strata = all_of(response))
    #pv_folds <- vfold_cv(pca_df, v = 10, strata = all_of(response))#should be the subset
    
    
    ranger_tune_results <- tune_grid(
      ranger_workflow,
      resamples = pv_folds,
      grid = ranger_grid,
      metrics = metric_set(rmse, rsq, mae))
    
     #plot performance metrics
    performance <- autoplot(ranger_tune_results, main = paste0(response, " ",  year_chr))
    plot(performance)
    #select best performing model and print metrics
    best_ranger_params <- select_best(ranger_tune_results, metric = "rmse")
    final_ranger_workflow <- finalize_workflow(ranger_workflow,
                                               best_ranger_params)
    
    #dimensionality reduction fit and important vars 
    final_ranger_fit <- fit(final_ranger_workflow, data = pv_dataframe)
    
    #see top principal component
    # importance_df <- vip(final_ranger_fit, num_features = 10)
    # top_feature <- importance_df$data$Variable[1]
    # 
    # #get the loadings of that component
    # pc_loadings <- pca$rotation[, paste0(top_feature)]
    # pc_loadings_df <- as.data.frame(pc_loadings) %>%
    #   rownames_to_column("Variable") %>%
    #   rename(Loading = pc_loadings) %>%
    #   arrange(desc(abs(Loading)))
    # head(pc_loadings_df, 10)
    # 
    # top_15_loadings <- pc_loadings_df %>%
    #   mutate(abs_loading = abs(Loading)) %>%
    #   arrange(desc(abs_loading)) %>%
    #   head(15)
    # 
    # #plot most important vars related to principal components
    # var_cont_plot <- ggplot(top_15_loadings, 
    #                         aes(x = reorder(Variable, abs(Loading)), y = Loading)) +
    #   geom_bar(stat = "identity", fill = "firebrick4") +
    #   coord_flip() +
    #   labs(title = paste0("Contribution to ", top_feature, " ", response, " ", year_chr),
    #        x = "Variable", y = "Abs. coefficient value") +
    #   theme_gray() +
    #   theme(
    #     axis.line.x = element_blank(),
    #     axis.text.x = element_blank(),  
    #     axis.ticks.x = element_blank(),
    #     plot.title = element_text(hjust = 0.5), 
    #     axis.title.x = element_blank()  
    #   )
    # plot(var_cont_plot)
    
    #get variance explained
    var_explained <- ranger_tune_results%>%
      collect_metrics()%>%
      filter(.metric == "rsq")%>%
      slice_max(mean, n=1)%>%#best rsq
      pull(mean)
      
    var_exp_df <- as.data.frame(var_explained)
    print(var_exp_df)
    #var_exp_df$rsq <- final_ranger_fit$fit$fit$fit$r.squared
    best_rmse <- ranger_tune_results%>%
      collect_metrics()%>%
      filter(.metric == "rmse")%>%
      slice_min(mean, n = 1) %>%#best rmse
      pull(mean)
    var_exp_df$rmse <- best_rmse
    
    var_exp_df$Species <- response
    var_exp_df$Year <- year
    write.csv(var_exp_df, paste0(out_dir_metrics, "RANGER_METRICS_",
                                 response, "_", year_chr, "V2", ".csv"), 
              row.names = FALSE,
              append = TRUE)
 
    # spatial prediction here // ranger expects df instead of raster
    fitted_model <- extract_fit_parsnip(final_ranger_fit)
    
    # #rename columns
    # names_of_top_vars <- names(pc_loadings)
    # names_of_top_vars <- setdiff(names_of_top_vars, response)

    # #read in RS composite from corresponding year
    #full_rs_composite <- pv_composites_all_bands[[list_id]]
    # full_rs_composite <- pv_composites[[list_id]]
    # final_vars <- fitted_model$fit$forest$independent.variable.names
    # #full_rs_composite_subset <- subset(full_rs_composite, final_vars)
    # 
    # #ranger expects a df
    # raster_df <- as.data.frame(full_rs_composite, xy = TRUE, na.rm = TRUE)
    # #raster_df_subset <- subset(raster_df, final_vars)
    # 
    # # #predict
    # # registerDoParallel(cores = parallel::detectCores() - 1)
    # prediction_values <- predict(fitted_model$fit, raster_df)
    # prediction_map <- cbind(raster_df[, c("x", "y")], prediction = prediction_values$predictions)
    # prediction_raster <- rast(prediction_map, type = "xyz")
    # crs(prediction_raster) <- crs(full_rs_composite)
    # plot(prediction_raster, main = paste0(response, " ", year))
    # # stopImplicitCluster()
    # 
    # file_name <- paste0("data/output/raster/Dalton_BIO", response, "_", year_chr, "V2.tif")
    # writeRaster(prediction_raster, file_name, overwrite = TRUE)
    # 
    # #plot(prediction_map, main = paste0(response, year_chr))
    # plot(prediction_map,
    #  main = paste0(response, year_chr),
    #  col = colorRampPalette(custom_palette)(100))
    # print(summary(prediction_map))
    # print(paste0("prediction map saved for:", response, "year", year_chr))

    
    #clear cache
    rm(pv_split, pv_train, 
       pv_test, pv_folds,ranger_tune_results,
       final_ranger_fit, ranger_grid, 
       pv_train_subset, pca, pca_df)
    #rm(prediction_values, prediction_raster, full_rs_composite)
    gc()
    
    model_metrics[[response]] <- var_exp_df
  }
  
  model_metrics_all_years[[year_chr]] <- model_metrics
}
#stopCluster(clus)
print(Sys.time())
```

